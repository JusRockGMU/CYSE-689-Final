#!/usr/bin/env python3
"""
Baseline Report Generator - Generate penetration testing reports using LLM without validation.

This module generates pentest reports from parsed Nmap facts using an LLM (Ollama).
NO validation is performed - this is the baseline for comparison against validated reports.

The reports include:
- Executive summary
- Technical findings
- Service analysis
- Recommendations

All output is generated purely from LLM reasoning without evidence checking.
"""

import argparse
import json
import ollama
from pathlib import Path
from typing import Dict, List, Any
from datetime import datetime
import sys


class BaselineReportGenerator:
    """Generate pentest reports using LLM without validation."""
    
    def __init__(self, model: str = "llama3.1:8b"):
        """Initialize generator with specified model."""
        self.model = model
        self.report_template = """# Penetration Testing Report

## Target Information
- **Target IP**: {target_ip}
- **Scan Date**: {scan_date}
- **Report Generated**: {report_date}

## Executive Summary

{executive_summary}

## Technical Findings

{technical_findings}

## Service Analysis

{service_analysis}

## Security Recommendations

{recommendations}

## Detailed Port Information

{port_details}

---
*Report generated by automated penetration testing system*
*Model: {model}*
"""
    
    def load_facts(self, facts_file: Path) -> Dict[str, Any]:
        """Load parsed facts from JSON file."""
        with open(facts_file, 'r') as f:
            return json.load(f)
    
    def generate_report(self, facts: Dict[str, Any]) -> str:
        """Generate complete pentest report from facts."""
        # Extract key information
        host_info = facts['hosts'][0] if facts['hosts'] else {}
        target_ip = host_info.get('addresses', {}).get('ipv4', 'Unknown')
        scan_date = facts['scan_info'].get('start_str', 'Unknown')
        summary = facts['summary']
        
        # Generate each section using LLM
        print(f"  Generating executive summary...")
        executive_summary = self._generate_executive_summary(facts)
        
        print(f"  Generating technical findings...")
        technical_findings = self._generate_technical_findings(facts)
        
        print(f"  Generating service analysis...")
        service_analysis = self._generate_service_analysis(facts)
        
        print(f"  Generating recommendations...")
        recommendations = self._generate_recommendations(facts)
        
        print(f"  Formatting port details...")
        port_details = self._format_port_details(facts)
        
        # Assemble report
        report = self.report_template.format(
            target_ip=target_ip,
            scan_date=scan_date,
            report_date=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            executive_summary=executive_summary,
            technical_findings=technical_findings,
            service_analysis=service_analysis,
            recommendations=recommendations,
            port_details=port_details,
            model=self.model
        )
        
        return report
    
    def _generate_executive_summary(self, facts: Dict[str, Any]) -> str:
        """Generate executive summary using LLM."""
        summary = facts['summary']
        services = ', '.join(summary['services_list'][:10])  # Top 10 services
        
        prompt = f"""You are a penetration tester writing an executive summary for a security assessment.

Target Information:
- {summary['open_ports']} open ports discovered
- {summary['unique_services']} unique services identified
- Services found: {services}

Write a concise executive summary (3-4 paragraphs) that:
1. Summarizes the scope of the assessment
2. Highlights the key findings
3. Provides overall risk assessment
4. States primary security concerns

Be direct and professional. Do not use markdown formatting in your response."""

        response = ollama.chat(
            model=self.model,
            messages=[{'role': 'user', 'content': prompt}]
        )
        
        return response['message']['content'].strip()
    
    def _generate_technical_findings(self, facts: Dict[str, Any]) -> str:
        """Generate detailed technical findings using LLM."""
        host = facts['hosts'][0] if facts['hosts'] else {}
        ports = host.get('ports', [])
        
        # Create concise port summary for LLM
        port_summary = []
        for port in ports[:15]:  # Limit to first 15 ports
            service = port.get('service', {})
            port_summary.append({
                'port': port['port'],
                'service': service.get('name', 'unknown'),
                'product': service.get('product', ''),
                'version': service.get('version', '')
            })
        
        prompt = f"""You are a penetration tester documenting technical findings.

Discovered Services:
{json.dumps(port_summary, indent=2)}

Write detailed technical findings that:
1. List each significant service discovery
2. Identify version information and known vulnerabilities
3. Assess potential attack vectors
4. Rank findings by severity (Critical, High, Medium, Low)

Format as numbered list with severity labels. Be specific about security implications."""

        response = ollama.chat(
            model=self.model,
            messages=[{'role': 'user', 'content': prompt}]
        )
        
        return response['message']['content'].strip()
    
    def _generate_service_analysis(self, facts: Dict[str, Any]) -> str:
        """Generate service-specific analysis using LLM."""
        host = facts['hosts'][0] if facts['hosts'] else {}
        ports = host.get('ports', [])
        os_info = host.get('os', {}).get('best_match', {})
        
        # Extract service details
        services_detail = []
        for port in ports[:10]:
            service = port.get('service', {})
            if service.get('name'):
                services_detail.append({
                    'name': service.get('name'),
                    'product': service.get('product', ''),
                    'version': service.get('version', ''),
                    'port': port['port']
                })
        
        os_name = os_info.get('name', 'Unknown')
        
        prompt = f"""You are analyzing services discovered during a penetration test.

Operating System: {os_name}

Services Detected:
{json.dumps(services_detail, indent=2)}

For each major service category (web, ssh, database, etc.), provide:
1. Service purpose and functionality
2. Common vulnerabilities for this version
3. Security configuration concerns
4. Recommended testing approaches

Be technical and specific. Focus on actionable security insights."""

        response = ollama.chat(
            model=self.model,
            messages=[{'role': 'user', 'content': prompt}]
        )
        
        return response['message']['content'].strip()
    
    def _generate_recommendations(self, facts: Dict[str, Any]) -> str:
        """Generate security recommendations using LLM."""
        summary = facts['summary']
        host = facts['hosts'][0] if facts['hosts'] else {}
        ports = host.get('ports', [])
        
        # Get service names
        services = [p.get('service', {}).get('name', '') for p in ports if p.get('service', {}).get('name')]
        
        prompt = f"""You are providing security recommendations for a penetration test.

Assessment Results:
- {summary['open_ports']} open ports
- {summary['unique_services']} services exposed
- Key services: {', '.join(services[:8])}

Provide prioritized security recommendations:
1. Immediate actions (Critical priority)
2. Short-term improvements (High priority)
3. Long-term security enhancements (Medium priority)
4. General hardening measures

Format as numbered lists under each category. Be specific and actionable."""

        response = ollama.chat(
            model=self.model,
            messages=[{'role': 'user', 'content': prompt}]
        )
        
        return response['message']['content'].strip()
    
    def _format_port_details(self, facts: Dict[str, Any]) -> str:
        """Format detailed port information from facts."""
        host = facts['hosts'][0] if facts['hosts'] else {}
        ports = host.get('ports', [])
        
        if not ports:
            return "No open ports detected."
        
        details = []
        for port in ports:
            service = port.get('service', {})
            
            port_info = f"""### Port {port['port']}/{port['protocol']}
**State**: {port['state']}  
**Service**: {service.get('name', 'unknown')}  
**Product**: {service.get('product', 'N/A')}  
**Version**: {service.get('version', 'N/A')}  
**Extra Info**: {service.get('extrainfo', 'N/A')}
"""
            
            # Add script outputs if present
            scripts = port.get('scripts', [])
            if scripts:
                port_info += "\n**NSE Script Results**:\n"
                for script in scripts[:3]:  # Limit to first 3 scripts
                    script_output = script['output'].replace('\n', ' ')[:100]  # Truncate long outputs
                    port_info += f"- {script['id']}: {script_output}...\n"
            
            details.append(port_info)
        
        return '\n'.join(details)


def generate_single_report(facts_file: Path, output_dir: Path, model: str) -> bool:
    """Generate report for a single facts file."""
    try:
        print(f"  Processing: {facts_file.name}")
        
        generator = BaselineReportGenerator(model=model)
        facts = generator.load_facts(facts_file)
        
        report = generator.generate_report(facts)
        
        # Save report
        output_file = output_dir / f"{facts_file.stem}_baseline.md"
        with open(output_file, 'w') as f:
            f.write(report)
        
        print(f"    [SUCCESS] Report saved to {output_file.name}")
        return True
        
    except Exception as e:
        print(f"    [ERROR] {e}")
        return False


def main():
    """Main entry point for baseline report generator."""
    parser = argparse.ArgumentParser(
        description='Generate baseline penetration testing reports using LLM (no validation).',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
Examples:
  # Generate baseline reports for all parsed facts
  python baseline_generator.py --facts data/parsed_facts --output data/reports/baseline
  
  # Generate report for single file
  python baseline_generator.py --facts data/parsed_facts/Bob-1.0.1.json --output data/reports/baseline
  
  # Limit to first 3 files (testing)
  python baseline_generator.py --facts data/parsed_facts --output data/reports/baseline --limit 3
        '''
    )
    
    parser.add_argument(
        '--facts', '-f',
        type=Path,
        required=True,
        help='Input JSON facts file or directory'
    )
    
    parser.add_argument(
        '--output', '-o',
        type=Path,
        required=True,
        help='Output directory for reports'
    )
    
    parser.add_argument(
        '--model', '-m',
        type=str,
        default='llama3.1:8b',
        help='Ollama model to use (default: llama3.1:8b)'
    )
    
    parser.add_argument(
        '--limit', '-l',
        type=int,
        default=None,
        help='Limit number of reports to generate (for testing)'
    )
    
    args = parser.parse_args()
    
    # Validate input
    if not args.facts.exists():
        print(f"[ERROR] Input path does not exist: {args.facts}")
        return 1
    
    # Create output directory
    args.output.mkdir(parents=True, exist_ok=True)
    
    # Get list of fact files
    if args.facts.is_file():
        fact_files = [args.facts]
    else:
        fact_files = sorted(args.facts.glob('*.json'))
    
    if not fact_files:
        print(f"[ERROR] No JSON files found in {args.facts}")
        return 1
    
    # Apply limit if specified
    if args.limit:
        fact_files = fact_files[:args.limit]
    
    # Generate reports
    print(f"\nGenerating {len(fact_files)} baseline report(s) using {args.model}...")
    print("=" * 60)
    
    success_count = 0
    for fact_file in fact_files:
        if generate_single_report(fact_file, args.output, args.model):
            success_count += 1
    
    print("=" * 60)
    print(f"\n[SUCCESS] Generated {success_count}/{len(fact_files)} report(s)")
    print(f"[OUTPUT] Reports saved to: {args.output}/")
    
    return 0 if success_count == len(fact_files) else 1


if __name__ == '__main__':
    sys.exit(main())
