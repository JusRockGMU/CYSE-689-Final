#!/usr/bin/env python3
"""
Validated Report Generator - Generate penetration testing reports with evidence validation.

This module extends the baseline generator by adding systematic evidence validation.
Reports are generated by the LLM, then validated against parsed scan facts. Unsupported
claims are flagged with warnings, and supported claims include evidence citations.

This represents the core innovation: evidence-grounded report generation with measurable
reduction in hallucinated claims.
"""

import argparse
import json
import ollama
from pathlib import Path
from typing import Dict, List, Any
from datetime import datetime
import sys

# Import our validator
from validator import EvidenceValidator, ValidationResult


class ValidatedReportGenerator:
    """Generate pentest reports with evidence validation."""
    
    def __init__(self, model: str = "llama3.1:8b"):
        """Initialize generator with specified model."""
        self.model = model
        self.report_template = """# Penetration Testing Report
**[EVIDENCE-VALIDATED]**

## Target Information
- **Target IP**: {target_ip}
- **Scan Date**: {scan_date}
- **Report Generated**: {report_date}
- **Validation Status**: {validation_status}

## Executive Summary

{executive_summary}

## Technical Findings

{technical_findings}

## Service Analysis

{service_analysis}

## Security Recommendations

{recommendations}

## Detailed Port Information

{port_details}

## Evidence Validation Summary

- **Total Claims**: {total_claims}
- **Supported Claims**: {supported_claims} ({support_rate:.1f}%)
- **Flagged Claims**: {flagged_claims} ({flag_rate:.1f}%)

{flagged_section}

---
*Report generated with evidence validation*
*Model: {model}*
*Unsupported claim rate: {flag_rate:.1f}%*
"""
    
    def load_facts(self, facts_file: Path) -> Dict[str, Any]:
        """Load parsed facts from JSON file."""
        with open(facts_file, 'r') as f:
            return json.load(f)
    
    def generate_report(self, facts: Dict[str, Any]) -> tuple[str, ValidationResult]:
        """Generate complete pentest report with validation."""
        # Extract key information
        host_info = facts['hosts'][0] if facts['hosts'] else {}
        target_ip = host_info.get('addresses', {}).get('ipv4', 'Unknown')
        scan_date = facts['scan_info'].get('start_str', 'Unknown')
        summary = facts['summary']
        
        # Generate LLM content (same as baseline)
        print(f"  Generating executive summary...")
        executive_summary = self._generate_executive_summary(facts)
        
        print(f"  Generating technical findings...")
        technical_findings = self._generate_technical_findings(facts)
        
        print(f"  Generating service analysis...")
        service_analysis = self._generate_service_analysis(facts)
        
        print(f"  Generating recommendations...")
        recommendations = self._generate_recommendations(facts)
        
        print(f"  Formatting port details...")
        port_details = self._format_port_details_with_evidence(facts)
        
        # Assemble initial report
        initial_report = f"""# Penetration Testing Report

## Executive Summary
{executive_summary}

## Technical Findings
{technical_findings}

## Service Analysis
{service_analysis}

## Security Recommendations
{recommendations}

## Detailed Port Information
{port_details}
"""
        
        # VALIDATE the report
        print(f"  Validating report against scan facts...")
        validator = EvidenceValidator(facts)
        validation = validator.validate_report(initial_report)
        
        # Generate flagged claims section
        flagged_section = self._generate_flagged_section(validation)
        
        # Determine validation status
        validation_status = self._get_validation_status(validation.hallucination_rate)
        
        # Assemble final report with validation info
        report = self.report_template.format(
            target_ip=target_ip,
            scan_date=scan_date,
            report_date=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            validation_status=validation_status,
            executive_summary=executive_summary,
            technical_findings=technical_findings,
            service_analysis=service_analysis,
            recommendations=recommendations,
            port_details=port_details,
            total_claims=validation.total_claims,
            supported_claims=validation.supported_claims,
            support_rate=validation.evidence_citation_rate,
            flagged_claims=validation.unsupported_claims,
            flag_rate=validation.hallucination_rate,
            flagged_section=flagged_section,
            model=self.model
        )
        
        return report, validation
    
    def _generate_executive_summary(self, facts: Dict[str, Any]) -> str:
        """Generate executive summary using LLM."""
        summary = facts['summary']
        services = ', '.join(summary['services_list'][:10])
        
        prompt = f"""You are a penetration tester writing an executive summary for a security assessment.

Target Information:
- {summary['open_ports']} open ports discovered
- {summary['unique_services']} unique services identified
- Services found: {services}

Write a concise executive summary (3-4 paragraphs) that:
1. Summarizes the scope of the assessment
2. Highlights the key findings
3. Provides overall risk assessment
4. States primary security concerns

IMPORTANT: Only mention services and ports that are explicitly provided above. Do not infer or assume additional services.

Be direct and professional. Do not use markdown formatting in your response."""

        response = ollama.chat(
            model=self.model,
            messages=[{'role': 'user', 'content': prompt}]
        )
        
        return response['message']['content'].strip()
    
    def _generate_technical_findings(self, facts: Dict[str, Any]) -> str:
        """Generate detailed technical findings using LLM with grounding constraints."""
        host = facts['hosts'][0] if facts['hosts'] else {}
        ports = host.get('ports', [])
        
        # Create concise port summary
        port_summary = []
        for port in ports[:15]:
            service = port.get('service', {})
            port_summary.append({
                'port': port['port'],
                'service': service.get('name', 'unknown'),
                'product': service.get('product', ''),
                'version': service.get('version', '')
            })
        
        prompt = f"""You are a penetration tester documenting technical findings.

Discovered Services (FROM SCAN):
{json.dumps(port_summary, indent=2)}

Write detailed technical findings that:
1. List each significant service discovery
2. Identify version information and potential vulnerabilities
3. Assess potential attack vectors
4. Rank findings by severity (Critical, High, Medium, Low)

CRITICAL CONSTRAINTS:
- Only reference ports, services, and versions EXACTLY as shown above
- Do not mention services not in the scan results
- When citing versions, use the exact version strings provided
- Clearly distinguish between confirmed findings and theoretical concerns

Format as numbered list with severity labels. Be specific about security implications."""

        response = ollama.chat(
            model=self.model,
            messages=[{'role': 'user', 'content': prompt}]
        )
        
        return response['message']['content'].strip()
    
    def _generate_service_analysis(self, facts: Dict[str, Any]) -> str:
        """Generate service-specific analysis using LLM."""
        host = facts['hosts'][0] if facts['hosts'] else {}
        ports = host.get('ports', [])
        os_info = host.get('os', {}).get('best_match', {})
        
        services_detail = []
        for port in ports[:10]:
            service = port.get('service', {})
            if service.get('name'):
                services_detail.append({
                    'name': service.get('name'),
                    'product': service.get('product', ''),
                    'version': service.get('version', ''),
                    'port': port['port']
                })
        
        os_name = os_info.get('name', 'Unknown')
        
        prompt = f"""You are analyzing services discovered during a penetration test.

Operating System: {os_name}

Services Detected:
{json.dumps(services_detail, indent=2)}

For each major service category, provide:
1. Service purpose and functionality
2. Common vulnerabilities for this version
3. Security configuration concerns
4. Recommended testing approaches

IMPORTANT: Only analyze services explicitly listed above. Reference versions exactly as shown.

Be technical and specific. Focus on actionable security insights."""

        response = ollama.chat(
            model=self.model,
            messages=[{'role': 'user', 'content': prompt}]
        )
        
        return response['message']['content'].strip()
    
    def _generate_recommendations(self, facts: Dict[str, Any]) -> str:
        """Generate security recommendations using LLM."""
        summary = facts['summary']
        host = facts['hosts'][0] if facts['hosts'] else {}
        ports = host.get('ports', [])
        
        services = [p.get('service', {}).get('name', '') for p in ports if p.get('service', {}).get('name')]
        
        prompt = f"""You are providing security recommendations for a penetration test.

Assessment Results:
- {summary['open_ports']} open ports
- {summary['unique_services']} services exposed
- Key services: {', '.join(services[:8])}

Provide prioritized security recommendations:
1. Immediate actions (Critical priority)
2. Short-term improvements (High priority)
3. Long-term security enhancements (Medium priority)
4. General hardening measures

Format as numbered lists under each category. Be specific and actionable."""

        response = ollama.chat(
            model=self.model,
            messages=[{'role': 'user', 'content': prompt}]
        )
        
        return response['message']['content'].strip()
    
    def _format_port_details_with_evidence(self, facts: Dict[str, Any]) -> str:
        """Format detailed port information with evidence markers."""
        host = facts['hosts'][0] if facts['hosts'] else {}
        ports = host.get('ports', [])
        
        if not ports:
            return "No open ports detected."
        
        details = []
        for port in ports:
            service = port.get('service', {})
            
            port_info = f"""### Port {port['port']}/{port['protocol']} [VERIFIED]
**State**: {port['state']}  
**Service**: {service.get('name', 'unknown')}  
**Product**: {service.get('product', 'N/A')}  
**Version**: {service.get('version', 'N/A')}  
**Extra Info**: {service.get('extrainfo', 'N/A')}
"""
            
            scripts = port.get('scripts', [])
            if scripts:
                port_info += "\n**NSE Script Results**:\n"
                for script in scripts[:3]:
                    script_output = script['output'].replace('\n', ' ')[:100]
                    port_info += f"- {script['id']}: {script_output}...\n"
            
            details.append(port_info)
        
        return '\n'.join(details)
    
    def _generate_flagged_section(self, validation: ValidationResult) -> str:
        """Generate section describing flagged claims."""
        if validation.unsupported_claims == 0:
            return "\nAll claims in this report were validated against scan data.\n"
        
        section = f"\n### Flagged Claims ({validation.unsupported_claims} total)\n\n"
        section += "The following claims could not be verified against scan data:\n\n"
        
        for claim in validation.claim_details:
            if not claim.supported:
                section += f"- **{claim.claim_type.capitalize()}**: {claim.value}\n"
                section += f"  - Context: {claim.context[:80]}...\n"
                section += f"  - Issue: {claim.evidence}\n\n"
        
        section += "*Note: Flagged claims may represent theoretical concerns or require additional verification.*\n"
        
        return section
    
    def _get_validation_status(self, hallucination_rate: float) -> str:
        """Determine validation status based on hallucination rate."""
        if hallucination_rate < 5:
            return "HIGH CONFIDENCE - Minimal unverified claims"
        elif hallucination_rate < 15:
            return "MODERATE CONFIDENCE - Some unverified claims present"
        elif hallucination_rate < 30:
            return "LOW CONFIDENCE - Multiple unverified claims"
        else:
            return "CAUTION - Significant unverified content"


def generate_single_report(facts_file: Path, output_dir: Path, model: str) -> bool:
    """Generate validated report for a single facts file."""
    try:
        print(f"  Processing: {facts_file.name}")
        
        generator = ValidatedReportGenerator(model=model)
        facts = generator.load_facts(facts_file)
        
        report, validation = generator.generate_report(facts)
        
        # Save report
        output_file = output_dir / f"{facts_file.stem}_validated.md"
        with open(output_file, 'w') as f:
            f.write(report)
        
        # Save validation metrics
        metrics_file = output_dir / f"{facts_file.stem}_metrics.json"
        metrics = {
            'total_claims': validation.total_claims,
            'supported_claims': validation.supported_claims,
            'unsupported_claims': validation.unsupported_claims,
            'evidence_citation_rate': validation.evidence_citation_rate,
            'hallucination_rate': validation.hallucination_rate,
            'claims_by_type': validation.claims_by_type,
            'unsupported_by_type': validation.unsupported_by_type
        }
        with open(metrics_file, 'w') as f:
            json.dump(metrics, f, indent=2)
        
        print(f"    [SUCCESS] Report saved - {validation.hallucination_rate:.1f}% unsupported claims")
        return True
        
    except Exception as e:
        print(f"    [ERROR] {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """Main entry point for validated report generator."""
    parser = argparse.ArgumentParser(
        description='Generate validated penetration testing reports with evidence checking.',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
Examples:
  # Generate validated reports for all parsed facts
  python validated_generator.py --facts data/parsed_facts --output data/reports/validated
  
  # Generate report for single file
  python validated_generator.py --facts data/parsed_facts/Bob-1.0.1.json --output data/reports/validated
  
  # Limit to first 3 files (testing)
  python validated_generator.py --facts data/parsed_facts --output data/reports/validated --limit 3
        '''
    )
    
    parser.add_argument(
        '--facts', '-f',
        type=Path,
        required=True,
        help='Input JSON facts file or directory'
    )
    
    parser.add_argument(
        '--output', '-o',
        type=Path,
        required=True,
        help='Output directory for reports'
    )
    
    parser.add_argument(
        '--model', '-m',
        type=str,
        default='llama3.1:8b',
        help='Ollama model to use (default: llama3.1:8b)'
    )
    
    parser.add_argument(
        '--limit', '-l',
        type=int,
        default=None,
        help='Limit number of reports to generate (for testing)'
    )
    
    args = parser.parse_args()
    
    # Validate input
    if not args.facts.exists():
        print(f"[ERROR] Input path does not exist: {args.facts}")
        return 1
    
    # Create output directory
    args.output.mkdir(parents=True, exist_ok=True)
    
    # Get list of fact files
    if args.facts.is_file():
        fact_files = [args.facts]
    else:
        fact_files = sorted(args.facts.glob('*.json'))
    
    if not fact_files:
        print(f"[ERROR] No JSON files found in {args.facts}")
        return 1
    
    # Apply limit if specified
    if args.limit:
        fact_files = fact_files[:args.limit]
    
    # Generate reports
    print(f"\nGenerating {len(fact_files)} validated report(s) using {args.model}...")
    print("=" * 60)
    
    success_count = 0
    for fact_file in fact_files:
        if generate_single_report(fact_file, args.output, args.model):
            success_count += 1
    
    print("=" * 60)
    print(f"\n[SUCCESS] Generated {success_count}/{len(fact_files)} report(s)")
    print(f"[OUTPUT] Reports saved to: {args.output}/")
    
    return 0 if success_count == len(fact_files) else 1


if __name__ == '__main__':
    sys.exit(main())
