# Evidence-Grounding: A Validator for LLM-Generated Penetration Testing Reports

## Overview

This project implements an evidence-grounding validation framework that reduces hallucinations in LLM-generated penetration testing reports by **79%** (from 4.2% to 0.9%). The system validates LLM-generated claims against structured Nmap scan data to flag unsupported assertions.

**Key Result**: 89% of reports achieved perfect accuracy (0% unsupported claims) with production-ready performance (<$0.01 cost, <1 minute per report).

---

## Quick Start (Makefile Workflow)

The entire project is automated through the Makefile. Run everything with simple commands:

### 1. Initial Setup

```bash
# Clone the repository
git clone https://github.com/JusRockGMU/CYSE-689-Final.git
cd CYSE-689-Final

# Set up environment (creates venv, installs dependencies)
make setup

# Check status
make status
```

### 2. Prerequisites

Install Ollama (https://ollama.ai) and pull the model:

```bash
ollama pull llama3.1:8b
```

**Optional**: For Claude comparison, create `.env` file:

```bash
echo "ANTHROPIC_API_KEY=your_key_here" > .env
```

### 3. Run the Complete Pipeline

```bash
# Run everything (parse → baseline → validated → claude → evaluate)
make all
```

Or run individual stages:

```bash
# Parse Nmap scans to JSON facts
make parse

# Generate baseline reports (Ollama without validation)
make baseline

# Generate validated reports (Ollama + validator)
make validated

# Generate Claude reports (Claude + validator) - requires API key
make claude

# Run 3-way comparison
make evaluate-three

# Quick 2-way comparison (skip Claude to save cost)
make quick
```

### 4. Clean Up

```bash
# Remove generated output (keeps venv)
make clean

# Complete reset (removes venv too)
make clean-all
```

---

## Available Makefile Targets

Run `make help` to see all available commands:

| Command | Description |
|---------|-------------|
| `make setup` | Create virtual environment and install dependencies |
| `make parse` | Parse Nmap XML scans to JSON facts |
| `make baseline` | Generate baseline reports (Ollama without validation) |
| `make validated` | Generate validated reports (Ollama + validator) |
| `make claude` | Generate Claude reports (Claude + validator) |
| `make evaluate-three` | Run 3-way comparison (Baseline vs Validated vs Claude) |
| `make all` | Run complete pipeline |
| `make quick` | Quick run (skip Claude to save cost) |
| `make download-scans` | Download additional scans from Vulnerable-Box-Resources (optional) |
| `make status` | Show project status |
| `make clean` | Remove generated output files |
| `make clean-all` | Remove output and virtual environment |
| `make ollama-check` | Check Ollama status and model |
| `make version` | Show version info |

---

## Architecture

```
Nmap XML Scans
      ↓
  Parser → JSON Facts
      ↓
   ┌──┴──────────┐
   ↓             ↓
Baseline      Validated
(Ollama only) (Ollama/Claude + Validator)
   ↓             ↓
   └──────┬──────┘
          ↓
    3-Way Evaluation
```

---

## Project Structure

```
CYSE-689-Final/
├── Makefile                      # Automation (run everything from here)
├── README.md                     # This file
├── requirements.txt              # Python dependencies (4 packages)
├── .gitignore                    # Git exclusions
│
├── src/                          # Source code (7 Python files)
│   ├── parser.py                 # Extract facts from Nmap XML
│   ├── validator.py              # Evidence-grounding validation
│   ├── baseline_generator.py     # Ollama without validation
│   ├── validated_generator.py    # Ollama with validation
│   ├── claude_generator.py       # Claude with validation
│   ├── evaluator.py              # Compute metrics per system
│   └── three_way_evaluator.py    # Compare all 3 systems
│
└── data/
    ├── DATASET_INFO.md           # Dataset documentation
    └── raw_scans/                # 20 Nmap XML files (VulnHub machines)
```

**Generated by pipeline** (gitignored):
- `output/parsed_facts/` - JSON facts extracted from scans
- `output/reports/baseline/` - Baseline reports
- `output/reports/validated/` - Validated reports
- `output/reports/claude/` - Claude reports
- `output/metrics/` - Evaluation results

---

## Core Components

### Parser (`parser.py`)
Extracts structured facts from Nmap XML scans:
- Open ports and protocols
- Service names and versions
- Operating system information

### Validator (`validator.py`)
Evidence-grounding validation with 12 bug fixes across 3 categories:
1. **Output Contamination**: Prevents self-referential validation
2. **Context Awareness**: Distinguishes recommendations from findings
3. **Semantic Matching**: Maps LLM terminology to Nmap naming (dns↔domain, smb↔netbios-ssn)

### Generators
- **Baseline**: Ollama llama3.1:8b (no validation)
- **Validated**: Ollama llama3.1:8b + validator
- **Claude**: Claude Haiku 3.5 + validator

### Evaluator (`three_way_evaluator.py`)
Computes comparative metrics:
- Unsupported claim rate
- Perfect report rate (0% unsupported)
- Statistical significance (t-tests, Cohen's d)

---

## Results Summary

| System | Unsupported Rate | Perfect Reports | Cost per Report |
|--------|------------------|-----------------|-----------------|
| Baseline | 4.2% | 51% (18/35) | $0.00 |
| Validated-Ollama | 2.0% | 63% (22/35) | $0.00 |
| Validated-Claude | 0.9% | 89% (31/35) | <$0.01 |

**Generalization**: Test set from independent source (HackTheBox) outperformed training set (VulnHub), proving no overfitting.

---

## Dataset

**Included**: 20 Nmap XML scans from VulnHub vulnerable machines:
- Metasploitable-2
- Kioptrix series  
- Bob, Chronos, DerpNStink, Devguru
- And 12 more (see [data/DATASET_INFO.md](data/DATASET_INFO.md))

**Optional**: Download 100+ additional scans:
```bash
make download-scans
```

This clones [Vulnerable-Box-Resources](https://github.com/InfoSecWarrior/Vulnerable-Box-Resources) for extended testing.

---

## Manual Usage (Without Makefile)

If you prefer to run Python scripts directly:

```bash
# Activate virtual environment
source venv/bin/activate

# Parse scans
python src/parser.py --input data/raw_scans --output output/parsed_facts

# Generate baseline reports
python src/baseline_generator.py --facts output/parsed_facts --output output/reports/baseline

# Generate validated reports
python src/validated_generator.py --facts output/parsed_facts --output output/reports/validated

# Evaluate
python src/evaluator.py --baseline output/reports/baseline --validated output/reports/validated --output output/metrics
```

---

## Requirements

- **Python 3.9+**
- **Ollama** (local LLM) - https://ollama.ai
- **Anthropic API key** (optional, for Claude comparison)

Dependencies (installed by `make setup`):
- `ollama` - Ollama LLM integration
- `anthropic` - Claude API client
- `fuzzywuzzy` - Fuzzy string matching for version validation
- `python-Levenshtein` - String similarity metrics

---

## Troubleshooting

### Ollama not running
```bash
make ollama-check  # Check status
# If not installed, visit https://ollama.ai
# If installed but not running, start it and pull the model:
ollama serve
ollama pull llama3.1:8b
```

### Virtual environment issues
```bash
make clean-all  # Remove everything
make setup      # Recreate from scratch
```

### Permission errors
```bash
chmod +x src/*.py  # Make scripts executable
```

---

## Course Information

**Course**: CYSE 689 - AI Methods for Cybersecurity  
**Institution**: George Mason University  
**Semester**: Fall 2025  
**Author**: Jake Rockwell

---

## Citation

If you use this code, please cite the accompanying paper:

> Rockwell, J. (2025). *Evidence-Grounding: A Validator for LLM-Generated Penetration Testing Reports*. CYSE 689 Final Project, George Mason University.

---

## License

Educational use only. See repository for details.
